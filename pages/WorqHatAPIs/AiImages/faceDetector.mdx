import { Callout, Tab, Tabs } from "nextra-theme-docs";

# Detecting and Analysing Faces with AI (Powered by ImageCon V2)

ImageCon V2 by WorqHat AI offers robust face analysis capabilities for images and videos. With ImageCon V2, you can detect faces within an image or video, and obtain valuable information about those faces. This includes the location of detected faces, facial landmarks such as the position of eyes, and attributes such as emotions (e.g., happiness or sadness) and the presence of glasses or face occlusion.

By submitting an image containing a face to ImageCon V2, the system will detect and analyze the facial attributes present. It provides a confidence score indicating the likelihood of a face being detected, along with detailed information about the facial attributes identified in the image.

Additionally, ImageCon V2 enables face-to-face comparison by allowing you to compare a face in one image with faces detected in another image. This feature can be useful for applications such as identity verification or searching for similar faces in a database.

ImageCon V2 by WorqHat AI empowers users to perform comprehensive face analysis, extracting key facial attributes and facilitating face-to-face comparisons. These capabilities have broad applications across industries, including security, identity verification, image search, and more.

## How does it work?

ImageCon V2 by WorqHat AI provides face analysis capabilities where it returns an object for each
detected face, containing information such as the bounding box, facial landmarks, quality, and
pose along-with predictions for gender, age, emotion, face occlusion, and more, with
corresponding confidence scores.

It's important to note that gender binary predictions made by ImageCon V2, based on physical appearance, should not be used to determine a person's gender identity. Similarly, emotion predictions are based on facial expressions and may not reflect an individual's actual internal emotional state. It is not recommended to make decisions impacting rights, privacy, or access to services solely based on these predictions.

To ensure accuracy in classification, it is advisable to use a threshold of 99% or higher,
particularly when negative impacts could arise from wrong classification. However, for Age Range,
ImageCon V2 estimates lower and upper age bounds, with wider ranges indicating lower confidence. Approximating the mid-point of the range can be used as a single value for age estimation.

One valuable use of these attributes is generating aggregate statistics. For instance, attributes like Smile, Pose, and Sharpness can be utilized to automatically select the "best profile picture" in a social media application. Additionally, anonymized demographic estimation based on predicted gender and age attributes can be employed for broader sample analysis, such as at events or retail stores.


<Callout type="info" emoji="ℹ️">
  <b>Info:</b> The face detection models used by ImageCon V2 are trained on real-world images of
  human faces. As a result, they may not
  support the detection of faces in cartoon/animated characters or non-human entities. If you want
  to detect cartoon characters in images or videos
</Callout>



## Use Cases

- **Facial Recognition and Identity Verification**: ImageCon V2 can be used for facial recognition
tasks, allowing for identity verification or authentication. This can be valuable in access control systems, secure authentication processes, or personalized user experiences.

- **Emotion Analysis and User Experience Enhancement**: By analyzing facial expressions and predicting emotions, ImageCon V2 can provide insights into user reactions and sentiments. This information can be leveraged to improve user experiences, personalize content, or tailor marketing strategies.

- **Audience Analysis and Demographics**: ImageCon V2's age and gender prediction capabilities can assist in analyzing the demographics of an audience or customer base. This information can be valuable for targeted marketing campaigns, product development, or understanding customer preferences.

- **Content Moderation**: The face analysis capabilities of ImageCon V2 can be utilized for content moderation purposes, identifying and flagging inappropriate or offensive images or videos that violate community guidelines or policies.

- **Personalized Recommendations**: By analyzing facial attributes such as age, gender, and emotions, ImageCon V2 can contribute to personalized recommendation systems. This can be used in e-commerce platforms, streaming services, or content delivery systems to provide tailored recommendations based on user characteristics.

- **Market Research and Advertising**: The facial analysis capabilities of ImageCon V2 can aid in market research by providing insights into consumer reactions to advertisements, product packaging, or promotional materials. This information can guide advertising strategies and help optimize marketing campaigns.

- **Augmented Reality (AR) and Virtual Reality (VR)**: ImageCon V2's face analysis capabilities can enhance AR and VR experiences by tracking facial landmarks and expressions. This enables interactive and immersive virtual overlays or animations that respond to user actions and emotions.

## How to use it?

### API Endpoint

````bash filename="API Endpoint" copy
https://api.worqhat.com/api/ai/images/v2/face-detection
````

### Headers


| Header Name |  Required  | Description |
|:---------| :------------: | :---------------- |
| x-api-key| ``true`` | This helps us to identify the User Sending the Request |
| x-org-key|  ``true`` | This helps us to identify the Workspace Associated with the Request. This helps users to maintain easier logs |

### Request Body

The Request Body is a JSON Object that contains the following fields:

| Data Type | Key | Value | Description |
|:---------| :------------: | :---------------- | :---------------- |
| File Object | image | ``The Image File that you want to Identify faces from`` | This is the Image File that you want to Identify faces from. The Image File should be sent as a Formdata Object and can be of any format.|

````json filename="Request Body (Formdata)" copy
{
    "image":"The Image File that you want to Identify faces from"
}
````

### Sample Code

You can use the following Endpoints on any Codebase, including client side codebases as long as
you are able to send the Headers and the Request Body to the API Endpoint. It's that easy! Just
send a POST Request to the API Endpoint with the Headers and the Request Body, and you are good to go!


<Tabs items={['cURL', 'Client JS', 'NodeJS', 'Python', 'Ruby', 'PHP', 'Java', 'GO', 'C']}>
  <Tab>
    ```` bash filename="cURL" copy
    curl --location 'https://api.worqhat.com/api/ai/images/v2/face-detection' \
    --header 'x-api-key: •••••••' \
    --header 'x-org-key: •••••••' \
    --form 'image=@"/C:/Users/ghosh/introduction.png"'
    ````
  </Tab>
  <Tab>
    ````js filename="Client JS fetch" copy
    var myHeaders = new Headers();
    myHeaders.append("x-api-key", "•••••••");
    myHeaders.append("x-org-key", "•••••••");

    var formdata = new FormData();
    formdata.append("image", fileInput.files[0], "introduction.png");

    var requestOptions = {
    method: 'POST',
    headers: myHeaders,
    body: formdata,
    redirect: 'follow'
  };

    fetch("https://api.worqhat.com/api/ai/images/v2/face-detection", requestOptions)
    .then(response => response.text())
    .then(result => console.log(result))
    .catch(error => console.log('error', error));
    ````

    ````js filename="Client JS XHR" copy
    var xhr = new XMLHttpRequest();
    var url = "https://api.worqhat.com/api/ai/images/v2/face-detection";
    xhr.open("POST", url, true);
    xhr.setRequestHeader("x-api-key", "•••••••");
    xhr.setRequestHeader("x-org-key", "•••••••");

    var formdata = new FormData();
    formdata.append("image", fileInput.files[0], "introduction.png");

    xhr.onreadystatechange = function () {
    if (xhr.readyState === 4 && xhr.status === 200) {
    var response = JSON.parse(xhr.responseText);
    console.log(response);
  }
  };

    xhr.onerror = function (error) {
    console.log('error', error);
  };

    xhr.send(formdata);

    ````
  </Tab>
  <Tab>
    ````js filename="NodeJS" copy
    const request = require('request');
    const fs = require('fs');

    const url = 'https://api.worqhat.com/api/ai/images/v2/face-detection';
    const apiKey = '•••••••';
    const orgKey = '•••••••';
    const filePath = 'path/to/introduction.png';

    const formData = {
    image: fs.createReadStream(filePath),
  };

    const requestOptions = {
    url: url,
    method: 'POST',
    headers: {
    'x-api-key': apiKey,
    'x-org-key': orgKey,
  },
    formData: formData,
  };

    request(requestOptions, function (error, response, body) {
    if (error) {
    console.log('Error:', error);
  } else {
    console.log('Response:', body);
  }
  });

    ````

    ````js filename="NodeJS Axios" copy
    const axios = require('axios');
    const fs = require('fs');

    const url = 'https://api.worqhat.com/api/ai/images/v2/face-detection';
    const apiKey = '•••••••';
    const orgKey = '•••••••';
    const filePath = 'path/to/introduction.png';

    const formData = new FormData();
    formData.append('image', fs.createReadStream(filePath));

    const config = {
    headers: {
    'x-api-key': apiKey,
    'x-org-key': orgKey,
    ...formData.getHeaders(),
  },
  };

    axios.post(url, formData, config)
    .then(response => {
    console.log('Response:', response.data);
  })
    .catch(error => {
    console.log('Error:', error);
  });

    ````
  </Tab>
  <Tab>
    ````py filename="Python Requests" copy
    import requests

    url = 'https://api.worqhat.com/api/ai/images/v2/face-detection'
    api_key = '•••••••'
    org_key = '•••••••'
    file_path = 'path/to/introduction.png'

    headers = {
    'x-api-key': api_key,
    'x-org-key': org_key
  }

    files = {'image': open(file_path, 'rb')}

    response = requests.post(url, headers=headers, files=files)

    if response.status_code == 200:
    print('Response:', response.json())
    else:
    print('Error:', response.text)

    ````
  </Tab>
  <Tab>
    ````ruby filename="Ruby" copy
    require 'httparty'

    url = 'https://api.worqhat.com/api/ai/images/v2/face-detection'
    api_key = '•••••••'
    org_key = '•••••••'
    file_path = 'path/to/introduction.png'

    headers = {
    'x-api-key' => api_key,
    'x-org-key' => org_key
  }

    response = HTTParty.post(url, headers: headers, body: {image: File.open(file_path)})

    if response.code == 200
    puts 'Response:', response.parsed_response
    else
    puts 'Error:', response.body
    end

    ````
  </Tab>
  <Tab>
    ````php filename="PHP" copy
    <?php

    $url = 'https://api.worqhat.com/api/ai/images/v2/face-detection';
    $api_key = '•••••••';
    $org_key = '•••••••';
    $file_path = 'path/to/introduction.png';

    $headers = array(
      'x-api-key: ' . $api_key,
      'x-org-key: ' . $org_key
    );

    $curl = curl_init();

    curl_setopt($curl, CURLOPT_URL, $url);
    curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);
    curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($curl, CURLOPT_POST, true);
    curl_setopt($curl, CURLOPT_POSTFIELDS, array('image' => new CurlFile($file_path)));

    $response = curl_exec($curl);

    if ($response === false) {
      echo 'Error: ' . curl_error($curl);
    } else {
      $http_code = curl_getinfo($curl, CURLINFO_HTTP_CODE);
      if ($http_code === 200) {
        echo 'Response: ' . $response;
      } else {
        echo 'Error: ' . $response;
      }
    }

    curl_close($curl);
    ?>

    ````
  </Tab>
  <Tab>
    ````java filename="Java" copy
    import okhttp3.MediaType;
    import okhttp3.OkHttpClient;
    import okhttp3.Request;
    import okhttp3.RequestBody;
    import okhttp3.Response;

    import java.io.File;
    import java.io.IOException;

    public class Main {
    public static void main(String[] args) throws IOException {
    String url = "https://api.worqhat.com/api/ai/images/v2/face-detection";
    String apiKey = "•••••••";
    String orgKey = "•••••••";
    String filePath = "path/to/introduction.png";

    File imageFile = new File(filePath);
    OkHttpClient client = new OkHttpClient();

    RequestBody requestBody = new MultipartBody.Builder()
    .setType(MultipartBody.FORM)
    .addFormDataPart("image", imageFile.getName(),
    RequestBody.create(MediaType.parse("image/*"), imageFile))
    .build();

    Request request = new Request.Builder()
    .url(url)
    .header("x-api-key", apiKey)
    .header("x-org-key", orgKey)
    .post(requestBody)
    .build();

    Response response = client.newCall(request).execute();
    if (response.isSuccessful()) {
    System.out.println("Response: " + response.body().string());
  } else {
    System.out.println("Error: " + response.body().string());
  }
  }
  }

    ````
  </Tab>
  <Tab>
    ````go filename="GO" copy
    package main

    import (
    "bytes"
    "fmt"
    "io"
    "mime/multipart"
    "net/http"
    "os"
    )

    func main() {
    url := "https://api.worqhat.com/api/ai/images/v2/face-detection"
    apiKey := "•••••••"
    orgKey := "•••••••"
    filePath := "path/to/introduction.png"

    file, err := os.Open(filePath)
    if err != nil {
    fmt.Println("Error opening file:", err)
    return
  }
    defer file.Close()

    body := &bytes.Buffer{}
    writer := multipart.NewWriter(body)
    part, err := writer.CreateFormFile("image", file.Name())
    if err != nil {
    fmt.Println("Error creating form file:", err)
    return
  }
    io.Copy(part, file)
    writer.Close()

    request, err := http.NewRequest("POST", url, body)
    if err != nil {
    fmt.Println("Error creating request:", err)
    return
  }
    request.Header.Set("x-api-key", apiKey)
    request.Header.Set("x-org-key", orgKey)
    request.Header.Set("Content-Type", writer.FormDataContentType())

    client := &http.Client{}
    response, err := client.Do(request)
    if err != nil {
    fmt.Println("Error sending request:", err)
    return
  }
    defer response.Body.Close()

    if response.StatusCode == http.StatusOK {
    fmt.Println("Response:", response.Body)
  } else {
    fmt.Println("Error:", response.Status)
  }
  }

    ````
  </Tab>
  <Tab>
    ````c filename="C" copy
    #include <stdio.h>
    #include <curl/curl.h>

    int main(void) {
    CURL * curl;
    CURLcode res;
    const char *url = "https://api.worqhat.com/api/ai/images/v2/face-detection";
    const char *apiKey = "•••••••";
    const char *orgKey = "•••••••";
    const char *filePath = "path/to/introduction.png";

    FILE *file = fopen(filePath, "rb");
    if (!file) {
    printf("Error opening file\n");
    return 1;
  }

    curl_global_init(CURL_GLOBAL_ALL);
    curl = curl_easy_init();
    if (curl) {
    struct curl_httppost *formpost = NULL;
    struct curl_httppost *lastptr = NULL;

    curl_formadd(&formpost, &lastptr,
    CURLFORM_COPYNAME, "image",
    CURLFORM_FILE, filePath,
    CURLFORM_END);

    curl_easy_setopt(curl, CURLOPT_URL, url);
    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, "Content-Type: multipart/form-data");
    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, "x-api-key: %s", apiKey);
    curl_easy_setopt(curl, CURLOPT_HTTPHEADER, "x-org-key: %s", orgKey);
    curl_easy_setopt(curl, CURLOPT_HTTPPOST, formpost);

    res = curl_easy_perform(curl);
    if (res != CURLE_OK) {
    printf("Error sending request: %s\n", curl_easy_strerror(res));
  } else {
    long response_code;
    curl_easy_getinfo(curl, CURLINFO_RESPONSE_CODE, &response_code);
    if (response_code == 200) {
    printf("Request succeeded\n");
  } else {
    printf("Request failed with code %ld\n", response_code);
  }
  }

    curl_formfree(formpost);
    curl_easy_cleanup(curl);
  }

    fclose(file);
    curl_global_cleanup();

    return 0;
  }

    ````
  </Tab>
</Tabs>


### Response

#### Table View

| Data Type |  Key  | Value                                  | Description                           |
|:---------| :------------: |:---------------------------------------|:--------------------------------------|
| String | id | `4a24ea32-3fbc-4667-ad78-d5bd1652a5cb` | Unique identifier for the API Request |
| String | status | `success` or `error`                   | Status of the API Request             |
| Number | timestamp | `1620120000`                           | Timestamp of the API Request          |
| Object | content | `{Key Value Pairs of Types}`   | The Analysis Results                |
| Number | processing_count | `6` | The Number of API Requests Processed |

#### JSON View

````json filename="JSON" copy
{
  "id": "edea3d37-01da-487a-8015-af712615beca",
  "status": "success",
  "timestamp": 1683406580856,
  "content": {
    "analysed_data": [
      {
        "BoundingBox": {
          "Width": 0.10777401179075241,
          "Height": 0.13282546401023865,
          "Left": 0.17654450237751007,
          "Top": 0.3921668529510498
        },
        "AgeRange": {
          "Low": 20,
          "High": 28
        },
        "Smile": {
          "Value": false,
          "Confidence": 93.70523071289062
        },
        "Eyeglasses": {
          "Value": true,
          "Confidence": 99.99999237060547
        },
        "Sunglasses": {
          "Value": false,
          "Confidence": 99.95690155029297
        },
        "Gender": {
          "Value": "Male",
          "Confidence": 99.96484375
        },
        "Beard": {
          "Value": false,
          "Confidence": 62.05418014526367
        },
        "Mustache": {
          "Value": false,
          "Confidence": 97.35452270507812
        },
        "EyesOpen": {
          "Value": true,
          "Confidence": 98.76431274414062
        },
        "MouthOpen": {
          "Value": true,
          "Confidence": 84.85880279541016
        },
        "Emotions": [
          {
            "Type": "SURPRISED",
            "Confidence": 92.99723815917969
          },
          {
            "Type": "CALM",
            "Confidence": 23.0799503326416
          },
          {
            "Type": "FEAR",
            "Confidence": 7.924409866333008
          },
          {
            "Type": "CONFUSED",
            "Confidence": 4.7363104820251465
          },
          {
            "Type": "SAD",
            "Confidence": 2.6062285900115967
          },
          {
            "Type": "ANGRY",
            "Confidence": 1.7453320026397705
          },
          {
            "Type": "HAPPY",
            "Confidence": 1.4428735971450806
          },
          {
            "Type": "DISGUSTED",
            "Confidence": 1.3754680156707764
          }
        ],
        "Landmarks": [
          {
            "Type": "eyeLeft",
            "X": 0.21465006470680237,
            "Y": 0.437491774559021
          },
          {
            "Type": "eyeRight",
            "X": 0.25979283452033997,
            "Y": 0.4359549283981323
          },
          {
            "Type": "mouthLeft",
            "X": 0.22244024276733398,
            "Y": 0.48688557744026184
          },
          {
            "Type": "mouthRight",
            "X": 0.2600334584712982,
            "Y": 0.4855155050754547
          },
          {
            "Type": "nose",
            "X": 0.2459861785173416,
            "Y": 0.4550646245479584
          },
          {
            "Type": "leftEyeBrowLeft",
            "X": 0.19446563720703125,
            "Y": 0.4297780692577362
          },
          {
            "Type": "leftEyeBrowRight",
            "X": 0.22514291107654572,
            "Y": 0.4198493957519531
          },
          {
            "Type": "leftEyeBrowUp",
            "X": 0.21060246229171753,
            "Y": 0.4192149043083191
          },
          {
            "Type": "rightEyeBrowLeft",
            "X": 0.25112780928611755,
            "Y": 0.4189653992652893
          },
          {
            "Type": "rightEyeBrowRight",
            "X": 0.2729511260986328,
            "Y": 0.42690983414649963
          },
          {
            "Type": "rightEyeBrowUp",
            "X": 0.2628464102745056,
            "Y": 0.41738104820251465
          },
          {
            "Type": "leftEyeLeft",
            "X": 0.2056843489408493,
            "Y": 0.43866878747940063
          },
          {
            "Type": "leftEyeRight",
            "X": 0.2234984040260315,
            "Y": 0.43773695826530457
          },
          {
            "Type": "leftEyeUp",
            "X": 0.21461336314678192,
            "Y": 0.4346442222595215
          },
          {
            "Type": "leftEyeDown",
            "X": 0.21498507261276245,
            "Y": 0.439727783203125
          },
          {
            "Type": "rightEyeLeft",
            "X": 0.250782310962677,
            "Y": 0.4368106424808502
          },
          {
            "Type": "rightEyeRight",
            "X": 0.2668272852897644,
            "Y": 0.43646448850631714
          },
          {
            "Type": "rightEyeUp",
            "X": 0.25996148586273193,
            "Y": 0.43306758999824524
          },
          {
            "Type": "rightEyeDown",
            "X": 0.25965967774391174,
            "Y": 0.4381241202354431
          },
          {
            "Type": "noseLeft",
            "X": 0.23344972729682922,
            "Y": 0.4658816158771515
          },
          {
            "Type": "noseRight",
            "X": 0.25016430020332336,
            "Y": 0.46519964933395386
          },
          {
            "Type": "mouthUp",
            "X": 0.2432977706193924,
            "Y": 0.47654277086257935
          },
          {
            "Type": "mouthDown",
            "X": 0.24340258538722992,
            "Y": 0.4926367402076721
          },
          {
            "Type": "leftPupil",
            "X": 0.21465006470680237,
            "Y": 0.437491774559021
          },
          {
            "Type": "rightPupil",
            "X": 0.25979283452033997,
            "Y": 0.4359549283981323
          },
          {
            "Type": "upperJawlineLeft",
            "X": 0.1773587167263031,
            "Y": 0.45201900601387024
          },
          {
            "Type": "midJawlineLeft",
            "X": 0.19171585142612457,
            "Y": 0.5035356879234314
          },
          {
            "Type": "chinBottom",
            "X": 0.24220940470695496,
            "Y": 0.5216568112373352
          },
          {
            "Type": "midJawlineRight",
            "X": 0.2716551721096039,
            "Y": 0.500251829624176
          },
          {
            "Type": "upperJawlineRight",
            "X": 0.27593758702278137,
            "Y": 0.4482903778553009
          }
        ],
        "Pose": {
          "Roll": -0.5706930756568909,
          "Yaw": 9.576250076293945,
          "Pitch": 21.39400863647461
        },
        "Quality": {
          "Brightness": 52.36806869506836,
          "Sharpness": 78.64350128173828
        },
        "Confidence": 99.99894714355469
      }
    ]
  },
  "processing_count": 1
}
````

The analyzed data returned by the API is structured as a JSON object and contains essential information about the detected faces. The `analysed_data` includes the total count of faces detected (`face_count`) and an array called `faces` that holds detailed information for each individual face.

Within the `faces` array, each face object is identified by a unique `face_id` and provides the following attributes: `face_rectangle`, `face_landmarks`, `pose`, `quality`, and `confidence`.

The `face_rectangle` attribute specifies the dimensions and position of the detected face within the image, including its `width`, `height`, `left` coordinate, and `top` coordinate.

The `face_landmarks` attribute contains specific facial landmarks, such as `eyeLeft`, `eyeRight`, `nose`, `mouthLeft`, and `mouthRight`. Each landmark is associated with `x` and `y` coordinates, indicating their positions on the face.

The `pose` attribute describes the face's rotation in terms of `roll`, `yaw`, and `pitch`. This information can be utilized to determine the face's orientation and adjust any visual elements accordingly.

The `quality` attribute provides insights into the face's attributes such as `brightness` and `sharpness`. This data can be useful for comparing faces across different images and identifying the best-quality face among them.

The `confidence` attribute represents the confidence level or certainty of the face detection process for the specific face. It indicates the reliability of the detection result, helping to gauge the accuracy of the detected face.

By combining the `face_rectangle` and `pose` data, developers can draw bounding boxes accurately around the detected faces within their applications. The `quality` attribute can aid in comparing faces, while the default `landmarks` provide key facial features for further analysis and manipulation.

Overall, the analyzed data from ImageCon V2 provides detailed information about each detected face, including their `location`, `landmarks`, `pose`, `quality`, and `confidence`. This data can be leveraged for various purposes, such as face visualization, face comparison, or further facial analysis.

### Error Codes

| Error Code | Description                                        |
|:---------|:---------------------------------------------------|
| 400 | Bad Request                                        |
| 401 | Unauthorized : Invalid API Key or Organization Key |
| 402 | Syntax Error : Invalid JSON                        |
